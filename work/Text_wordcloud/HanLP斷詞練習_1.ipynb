{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安裝 HanLP 套件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://github.com/hankcs/pyhanlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jovyan/.cache/pip/wheels/45/4d/85/30a65b3238905586c0346816c0d8ce88e937ff8a12563cfe88/hanlp-2.0.0a46-py3-none-any.whl\n",
      "Collecting tensorflow==2.1.0\n",
      "  Using cached tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n",
      "Collecting bert-for-tf2==0.12.7\n",
      "  Using cached bert-for-tf2-0.12.7.tar.gz (39 kB)\n",
      "Collecting fasttext==0.9.1\n",
      "  Using cached fasttext-0.9.1.tar.gz (57 kB)\n",
      "Collecting sentencepiece==0.1.85\n",
      "  Using cached sentencepiece-0.1.85-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting py-params==0.8.2\n",
      "  Using cached py-params-0.8.2.tar.gz (4.5 kB)\n",
      "Collecting params-flow==0.7.4\n",
      "  Using cached params-flow-0.7.4.tar.gz (19 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0->hanlp) (0.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0->hanlp) (1.29.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0->hanlp) (1.12.1)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Using cached tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0->hanlp) (1.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0->hanlp) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0->hanlp) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0->hanlp) (0.9.0)\n",
      "Collecting astor>=0.6.0\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0->hanlp) (3.2.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0->hanlp) (3.11.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0->hanlp) (1.15.0)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Using cached tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0->hanlp) (1.18.5)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting gast==0.2.2\n",
      "  Using cached gast-0.2.2.tar.gz (10 kB)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0->hanlp) (0.34.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1->hanlp) (2.5.0)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1->hanlp) (47.3.1.post20200616)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from params-flow==0.7.4->hanlp) (4.46.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (3.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (1.17.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (2.24.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==2.1.0->hanlp) (2.10.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (1.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (4.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (4.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (2020.4.5.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (1.25.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (3.0.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->hanlp) (0.4.8)\n",
      "Building wheels for collected packages: bert-for-tf2, fasttext, py-params, params-flow, gast\n",
      "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.12.7-py3-none-any.whl size=29175 sha256=d8e6aff1d80a4d24cd808f1367d75ca05cb0b28371c2c98d4025e6157a290578\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/86/9f/cb/7fb7fb97ac89abbb6ef03fa5f7ec0b2f156a2e689b8c844559\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fasttext: filename=fasttext-0.9.1-cp37-cp37m-linux_x86_64.whl size=3535012 sha256=30516d0e241cd4a9496e9fcc9f42d512029f52e2c370e8c9bb62e37b27418fba\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/b2/5b/4b/9c582c778bb93aaad8fc855d5e79f49eae34f59e363a22c422\n",
      "  Building wheel for py-params (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-params: filename=py_params-0.8.2-py3-none-any.whl size=4632 sha256=703654df0295792d0644197533d79aa425d14d66edf705914129f05a59594c36\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/13/9f/aa/9e5fd52c299f5142e72e2ede958d6c8957af97b981fac7d2b0\n",
      "  Building wheel for params-flow (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for params-flow: filename=params_flow-0.7.4-py3-none-any.whl size=16194 sha256=0b66706894d5dbf3a4cddedfb6e94c9c1f5bd0bb5607e4e41ea05c6cb28950fd\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/bc/67/e9/fec9c0b1a52099b2e2b5a8ed14fa307cffc718a2a986aef675\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=4b14d1d6e8a51ec01b293cf21c854c845fd642057f1b8eb63a89e3e27eebab18\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
      "Successfully built bert-for-tf2 fasttext py-params params-flow gast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tensorboard, astor, tensorflow-estimator, keras-applications, gast, tensorflow, py-params, params-flow, bert-for-tf2, fasttext, sentencepiece, hanlp\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.2.2\n",
      "    Uninstalling tensorboard-2.2.2:\n",
      "      Successfully uninstalled tensorboard-2.2.2\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.2.0\n",
      "    Uninstalling tensorflow-estimator-2.2.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.2.0\n",
      "    Uninstalling tensorflow-2.2.0:\n",
      "      Successfully uninstalled tensorflow-2.2.0\n",
      "Successfully installed astor-0.8.1 bert-for-tf2-0.12.7 fasttext-0.9.1 gast-0.2.2 hanlp-2.0.0a46 keras-applications-1.0.8 params-flow-0.7.4 py-params-0.8.2 sentencepiece-0.1.85 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hanlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hanlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '歐幾里得 西元前三世紀的古希臘數學家 現在被認為是幾何之父'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下載繁體字的辭典檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big -O jieba_data/dict.txt.big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入 Jieba 套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢查 Jieba 版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指定辭典檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.set_dictionary('jieba_data/dict.txt.big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -10 jieba_data/dict.txt.big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 斷詞簡介"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_str = '今天天氣真好'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?jieba.cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精確模式斷詞 (cut_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_result = jieba.cut(text_str, cut_all=False)\n",
    "print(' / '.join(list(seg_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全模式斷詞 (cut_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_result = jieba.cut(text_str, cut_all=True)\n",
    "print(' / '.join(list(seg_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 搜尋模式斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?jieba.cut_for_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_result = jieba.cut_for_search(text_str, HMM=True)\n",
    "print(' / '.join(list(seg_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_result = jieba.cut_for_search(text_str, HMM=False)\n",
    "print(' / '.join(list(seg_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paddle 模式斷詞 (use_paddle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.enable_paddle()\n",
    "seg_result = jieba.cut(text_str, use_paddle=True)\n",
    "print(' / '.join(list(seg_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 詞性標註"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 詞性說明: https://gist.github.com/luw2007/6016931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.posseg as pseg\n",
    "jieba.enable_paddle()\n",
    "seg_result = pseg.lcut(text_str, use_paddle=True)\n",
    "for w, p in seg_result:\n",
    "    print(\"%s, %s\"%(w, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定義詞庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_str_2 = '是在哈囉嗎?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_result = jieba.lcut(text_str_2)\n",
    "print(' / '.join(seg_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.load_userdict('jieba_data/mydict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_result = jieba.lcut(text_str_2)\n",
    "print(' / '.join(seg_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat jieba_data/mydict.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 停止字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/fxsjy/jieba/master/extra_dict/stop_words.txt -O jieba_data/stop_words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -5 jieba_data/stop_words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_list = []\n",
    "with open(file='jieba_data/stop_words.txt',mode='r', encoding=\"UTF-8\") as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        stop_words_list.append(line)\n",
    "stop_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_str_3 = '我是一位小學生，從小學習鋼琴，希望成為youtuber'\n",
    "seg_result = jieba.lcut(text_str_3)\n",
    "seg_result_stopword = []\n",
    "for term in seg_result:\n",
    "    if term not in stop_words_list:\n",
    "        seg_result_stopword.append(term)\n",
    "seg_result_stopword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jieba.DEFAULT_DICT_NAME)\n",
    "# check jieba/jieba/__init__.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
