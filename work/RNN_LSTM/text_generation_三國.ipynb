{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t09eeeR5prIJ"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:27.948396Z",
     "iopub.status.busy": "2020-09-22T23:11:27.947732Z",
     "iopub.status.idle": "2020-09-22T23:11:27.950222Z",
     "shell.execute_reply": "2020-09-22T23:11:27.949606Z"
    },
    "id": "GCCk8_dHpuNf"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovpZyIhNIgoq"
   },
   "source": [
    "# 循环神经网络（RNN）文本生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcD2nPQvPOFM"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://tensorflow.google.cn/tutorials/text/text_generation\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\" />在 tensorflow.google.cn 上查看</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/text/text_generation.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\" />在 Google Colab 运行</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/text/text_generation.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\" />在 GitHub 上查看源代码</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/tutorials/text/text_generation.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\" />下载此 notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwpJ5IffzRG6"
   },
   "source": [
    "本教程演示如何使用基于字符的 RNN 生成文本。我们将使用 Andrej Karpathy 在[《循环神经网络不合理的有效性》](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)一文中提供的莎士比亚作品数据集。给定此数据中的一个字符序列 （“Shakespear”），训练一个模型以预测该序列的下一个字符（“e”）。通过重复调用该模型，可以生成更长的文本序列。\n",
    "\n",
    "请注意：启用 GPU 加速可以更快地执行此笔记本。在 Colab 中依次选择：*运行时 > 更改运行时类型 > 硬件加速器 > GPU*。如果在本地运行，请确保 TensorFlow 的版本为 1.11 或更高。\n",
    "\n",
    "本教程包含使用 [tf.keras](https://tensorflow.google.cn/programmers_guide/keras) 和 [eager execution](https://tensorflow.google.cn/programmers_guide/eager) 实现的可运行代码。以下是当本教程中的模型训练 30 个周期 （epoch），并以字符串 “Q” 开头时的示例输出：\n",
    "\n",
    "<pre>\n",
    "QUEENE:\n",
    "I had thought thou hadst a Roman; for the oracle,\n",
    "Thus by All bids the man against the word,\n",
    "Which are so weak of care, by old care done;\n",
    "Your children were in your holy love,\n",
    "And the precipitation through the bleeding throne.\n",
    "\n",
    "BISHOP OF ELY:\n",
    "Marry, and will, my lord, to weep in such a one were prettiest;\n",
    "Yet now I was adopted heir\n",
    "Of the world's lamentable day,\n",
    "To watch the next way with his father with his face?\n",
    "\n",
    "ESCALUS:\n",
    "The cause why then we are all resolved more sons.\n",
    "\n",
    "VOLUMNIA:\n",
    "O, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, it is no sin it should be dead,\n",
    "And love and pale as any will to that word.\n",
    "\n",
    "QUEEN ELIZABETH:\n",
    "But how long have I heard the soul for this world,\n",
    "And show his hands of life be proved to stand.\n",
    "\n",
    "PETRUCHIO:\n",
    "I say he look'd on, if I must be content\n",
    "To stay him from the fatal of our country's bliss.\n",
    "His lordship pluck'd from this sentence then for prey,\n",
    "And then let us twain, being the moon,\n",
    "were she such a case as fills m\n",
    "</pre>\n",
    "\n",
    "虽然有些句子符合语法规则，但是大多数句子没有意义。这个模型尚未学习到单词的含义，但请考虑以下几点：\n",
    "\n",
    "* 此模型是基于字符的。训练开始时，模型不知道如何拼写一个英文单词，甚至不知道单词是文本的一个单位。\n",
    "\n",
    "* 输出文本的结构类似于剧本 -- 文本块通常以讲话者的名字开始；而且与数据集类似，讲话者的名字采用全大写字母。\n",
    "\n",
    "* 如下文所示，此模型由小批次 （batch） 文本训练而成（每批 100 个字符）。即便如此，此模型仍然能生成更长的文本序列，并且结构连贯。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srXC6pLGLwS6"
   },
   "source": [
    "## 设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGyKZj3bzf9p"
   },
   "source": [
    "### 导入 TensorFlow 和其他库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:27.954616Z",
     "iopub.status.busy": "2020-09-22T23:11:27.953788Z",
     "iopub.status.idle": "2020-09-22T23:11:34.241819Z",
     "shell.execute_reply": "2020-09-22T23:11:34.241105Z"
    },
    "id": "yG_n40gFzf9s"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHDoRoc5PKWz"
   },
   "source": [
    "### 下载莎士比亚数据集\n",
    "\n",
    "修改下面一行代码，在你自己的数据上运行此代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:34.247817Z",
     "iopub.status.busy": "2020-09-22T23:11:34.247165Z",
     "iopub.status.idle": "2020-09-22T23:11:34.365937Z",
     "shell.execute_reply": "2020-09-22T23:11:34.365421Z"
    },
    "id": "pD_55cOxLkAb"
   },
   "outputs": [],
   "source": [
    "path_to_file = \"../Three Kingdoms.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHjdCjDuSvX_"
   },
   "source": [
    "### 读取数据\n",
    "\n",
    "首先，看一看文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:34.370885Z",
     "iopub.status.busy": "2020-09-22T23:11:34.370190Z",
     "iopub.status.idle": "2020-09-22T23:11:34.375208Z",
     "shell.execute_reply": "2020-09-22T23:11:34.374615Z"
    },
    "id": "aavnuByVymwK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 621494 characters\n"
     ]
    }
   ],
   "source": [
    "# 读取并为 py2 compat 解码\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "# 文本长度是指文本中的字符个数\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:34.379237Z",
     "iopub.status.busy": "2020-09-22T23:11:34.378588Z",
     "iopub.status.idle": "2020-09-22T23:11:34.381407Z",
     "shell.execute_reply": "2020-09-22T23:11:34.380824Z"
    },
    "id": "Duhg9NrUymwO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《三國演義》作者：羅貫中\n",
      "\n",
      "簡介\n",
      "　　三國演義是一本長篇歷史小說，可以說是中國古代長篇章回小說的開山之作，亦是四大名著之一。作者是明朝的羅貫中。故事自黃巾起義起，終於西晉統一。是書陳敘百年，賅括萬事，七實三虛。三國指的是魏，蜀，吳。小說通篇精巧敘述謀略，被譽為中國謀略全書。\n",
      "　　羅貫中（1330年一1400年之間），名本，號湖海散人，明代通俗小說家。他的籍貫一說是太原（今山西），一說是錢塘（今浙江杭州），不可確考。據傳說，羅貫中曾充任過元末農民起義軍張士誠的幕客．除《三國誌通俗演義》外，\n"
     ]
    }
   ],
   "source": [
    "# 看一看文本中的前 250 个字符\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:34.398268Z",
     "iopub.status.busy": "2020-09-22T23:11:34.397463Z",
     "iopub.status.idle": "2020-09-22T23:11:34.399680Z",
     "shell.execute_reply": "2020-09-22T23:11:34.400217Z"
    },
    "id": "IlCgQBRVymwR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4024 unique characters\n"
     ]
    }
   ],
   "source": [
    "# 文本中的非重复字符\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNnrKn_lL-IJ"
   },
   "source": [
    "## 处理文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFjSVAlWzf-N"
   },
   "source": [
    "### 向量化文本\n",
    "\n",
    "在训练之前，我们需要将字符串映射到数字表示值。创建两个查找表格：一个将字符映射到数字，另一个将数字映射到字符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:34.449640Z",
     "iopub.status.busy": "2020-09-22T23:11:34.423682Z",
     "iopub.status.idle": "2020-09-22T23:11:34.573228Z",
     "shell.execute_reply": "2020-09-22T23:11:34.572456Z"
    },
    "id": "y0FUEx8jjmLk"
   },
   "outputs": [],
   "source": [
    "# 创建从非重复字符到索引的映射\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZfqhkYCymwX"
   },
   "source": [
    "现在，每个字符都有一个整数表示值。请注意，我们将字符映射至索引 0 至 `len(unique)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:34.579687Z",
     "iopub.status.busy": "2020-09-22T23:11:34.578609Z",
     "iopub.status.idle": "2020-09-22T23:11:34.584783Z",
     "shell.execute_reply": "2020-09-22T23:11:34.584166Z"
    },
    "id": "FYyNlCNXymwY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  '\\r':   1,\n",
      "  ' ' :   2,\n",
      "  '.' :   3,\n",
      "  '0' :   4,\n",
      "  '1' :   5,\n",
      "  '2' :   6,\n",
      "  '3' :   7,\n",
      "  '4' :   8,\n",
      "  '5' :   9,\n",
      "  '6' :  10,\n",
      "  '7' :  11,\n",
      "  '8' :  12,\n",
      "  '9' :  13,\n",
      "  '?' :  14,\n",
      "  '[' :  15,\n",
      "  ']' :  16,\n",
      "  '—' :  17,\n",
      "  '…' :  18,\n",
      "  '□' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:34.590023Z",
     "iopub.status.busy": "2020-09-22T23:11:34.589260Z",
     "iopub.status.idle": "2020-09-22T23:11:34.592753Z",
     "shell.execute_reply": "2020-09-22T23:11:34.592128Z"
    },
    "id": "l1VKcQHcymwb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'《三國演義》作者：羅貫中\\r' ---- characters mapped to int ---- > [  23   33  595 1986 2703   24  139 2727 4021 2694 3253   47    1]\n"
     ]
    }
   ],
   "source": [
    "# 显示文本首 13 个字符的整数映射\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbmsf23Bymwe"
   },
   "source": [
    "### 预测任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wssHQ1oGymwe"
   },
   "source": [
    "给定一个字符或者一个字符序列，下一个最可能出现的字符是什么？这就是我们训练模型要执行的任务。输入进模型的是一个字符序列，我们训练这个模型来预测输出 -- 每个时间步（time step）预测下一个字符是什么。\n",
    "\n",
    "由于 RNN 是根据前面看到的元素维持内部状态，那么，给定此时计算出的所有字符，下一个字符是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### 创建训练样本和目标\n",
    "\n",
    "接下来，将文本划分为样本序列。每个输入序列包含文本中的 `seq_length` 个字符。\n",
    "\n",
    "对于每个输入序列，其对应的目标包含相同长度的文本，但是向右顺移一个字符。\n",
    "\n",
    "将文本拆分为长度为 `seq_length+1` 的文本块。例如，假设 `seq_length` 为 4 而且文本为 “Hello”， 那么输入序列将为 “Hell”，目标序列将为 “ello”。\n",
    "\n",
    "为此，首先使用 `tf.data.Dataset.from_tensor_slices` 函数把文本向量转换为字符索引流。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:36.017708Z",
     "iopub.status.busy": "2020-09-22T23:11:36.016944Z",
     "iopub.status.idle": "2020-09-22T23:11:36.034623Z",
     "shell.execute_reply": "2020-09-22T23:11:36.033998Z"
    },
    "id": "mQ1jrAoVjmLu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《\n",
      "三\n",
      "國\n",
      "演\n",
      "義\n"
     ]
    }
   ],
   "source": [
    "# 设定每个输入句子长度的最大值\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "\n",
    "# 创建训练样本 / 目标\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZSYAcQV8OGP"
   },
   "source": [
    "`batch` 方法使我们能轻松把单个字符转换为所需长度的序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:36.039520Z",
     "iopub.status.busy": "2020-09-22T23:11:36.038918Z",
     "iopub.status.idle": "2020-09-22T23:11:36.049226Z",
     "shell.execute_reply": "2020-09-22T23:11:36.048664Z"
    },
    "id": "l4hkDU3i7ozi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'《三國演義》作者：羅貫中\\r\\n\\r\\n簡介\\r\\n\\u3000\\u3000三國演義是一本長篇歷史小說，可以說是中國古代長篇章回小說的開山之作，亦是四大名著之一。作者是明朝的羅貫中。故事自黃巾起義起，終於西晉統一。是書陳敘百年，賅括萬'\n",
      "'事，七實三虛。三國指的是魏，蜀，吳。小說通篇精巧敘述謀略，被譽為中國謀略全書。\\r\\n\\u3000\\u3000羅貫中（1330年一1400年之間），名本，號湖海散人，明代通俗小說家。他的籍貫一說是太原（今山西），一說是錢塘（今'\n",
      "'浙江杭州），不可確考。據傳說，羅貫中曾充任過元末農民起義軍張士誠的幕客．除《三國誌通俗演義》外，他還創作有《隋唐志傳》等通俗小說和《趙太祖龍虎風雲會》等戲劇。另外，有相當一部分人認為《水滸傳》後三十回也'\n",
      "'是其所作。\\r\\n\\r\\n目錄\\r\\n\\r\\n第001回\\u3000宴桃園豪傑三結義\\u3000斬黃巾英雄首立功 第002回\\u3000張翼德怒鞭督郵\\u3000何國舅謀誅宦豎 \\r\\n第003回\\u3000議溫明董卓叱丁原\\u3000饋金珠李肅說呂布 第004回\\u3000廢漢帝陳留踐位\\u3000'\n",
      "'謀董賊孟德獻刀 \\r\\n第005回\\u3000發矯詔諸鎮應曹公\\u3000破關兵三英戰呂布 第006回\\u3000焚金闕董卓行兇\\u3000匿玉璽孫堅背約 \\r\\n第007回\\u3000袁紹磐河戰公孫\\u3000孫堅跨江擊劉表 第008回\\u3000王司徒巧使連環計\\u3000董太師大鬧鳳'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbLcIPBj_mWZ"
   },
   "source": [
    "对于每个序列，使用 `map` 方法先复制再顺移，以创建输入文本和目标文本。`map` 方法可以将一个简单的函数应用到每一个批次 （batch）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:36.056193Z",
     "iopub.status.busy": "2020-09-22T23:11:36.055564Z",
     "iopub.status.idle": "2020-09-22T23:11:36.119177Z",
     "shell.execute_reply": "2020-09-22T23:11:36.118576Z"
    },
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiCopyGZymwi"
   },
   "source": [
    "打印第一批样本的输入与目标值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:36.124926Z",
     "iopub.status.busy": "2020-09-22T23:11:36.124195Z",
     "iopub.status.idle": "2020-09-22T23:11:36.145590Z",
     "shell.execute_reply": "2020-09-22T23:11:36.145077Z"
    },
    "id": "GNbw-iR0ymwj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  '《三國演義》作者：羅貫中\\r\\n\\r\\n簡介\\r\\n\\u3000\\u3000三國演義是一本長篇歷史小說，可以說是中國古代長篇章回小說的開山之作，亦是四大名著之一。作者是明朝的羅貫中。故事自黃巾起義起，終於西晉統一。是書陳敘百年，賅括'\n",
      "Target data: '三國演義》作者：羅貫中\\r\\n\\r\\n簡介\\r\\n\\u3000\\u3000三國演義是一本長篇歷史小說，可以說是中國古代長篇章回小說的開山之作，亦是四大名著之一。作者是明朝的羅貫中。故事自黃巾起義起，終於西晉統一。是書陳敘百年，賅括萬'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_33OHL3b84i0"
   },
   "source": [
    "这些向量的每个索引均作为一个时间步来处理。作为时间步 0 的输入，模型接收到 “F” 的索引，并尝试预测 “i” 的索引为下一个字符。在下一个时间步，模型执行相同的操作，但是 `RNN` 不仅考虑当前的输入字符，还会考虑上一步的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:36.151017Z",
     "iopub.status.busy": "2020-09-22T23:11:36.150362Z",
     "iopub.status.idle": "2020-09-22T23:11:36.471140Z",
     "shell.execute_reply": "2020-09-22T23:11:36.471578Z"
    },
    "id": "0eBu9WZG84i0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 23 ('《')\n",
      "  expected output: 33 ('三')\n",
      "Step    1\n",
      "  input: 33 ('三')\n",
      "  expected output: 595 ('國')\n",
      "Step    2\n",
      "  input: 595 ('國')\n",
      "  expected output: 1986 ('演')\n",
      "Step    3\n",
      "  input: 1986 ('演')\n",
      "  expected output: 2703 ('義')\n",
      "Step    4\n",
      "  input: 2703 ('義')\n",
      "  expected output: 24 ('》')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJdfPmdqzf-R"
   },
   "source": [
    "### 创建训练批次\n",
    "\n",
    "前面我们使用 `tf.data` 将文本拆分为可管理的序列。但是在把这些数据输送至模型之前，我们需要将数据重新排列 （shuffle） 并打包为批次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:36.476297Z",
     "iopub.status.busy": "2020-09-22T23:11:36.475688Z",
     "iopub.status.idle": "2020-09-22T23:11:36.486788Z",
     "shell.execute_reply": "2020-09-22T23:11:36.487201Z"
    },
    "id": "p2pGotuNzf-S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 批大小\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 设定缓冲区大小，以重新排列数据集\n",
    "# （TF 数据被设计为可以处理可能是无限的序列，\n",
    "# 所以它不会试图在内存中重新排列整个序列。相反，\n",
    "# 它维持一个缓冲区，在缓冲区重新排列元素。） \n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8gPwEjRzf-Z"
   },
   "source": [
    "使用 `tf.keras.Sequential` 定义模型。在这个简单的例子中，我们使用了三个层来定义模型：\n",
    "\n",
    "* `tf.keras.layers.Embedding`：输入层。一个可训练的对照表，它会将每个字符的数字映射到一个 `embedding_dim` 维度的向量。 \n",
    "* `tf.keras.layers.GRU`：一种 RNN 类型，其大小由 `units=rnn_units` 指定（这里你也可以使用一个 LSTM 层）。\n",
    "* `tf.keras.layers.Dense`：输出层，带有 `vocab_size` 个输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:36.491389Z",
     "iopub.status.busy": "2020-09-22T23:11:36.490743Z",
     "iopub.status.idle": "2020-09-22T23:11:36.493108Z",
     "shell.execute_reply": "2020-09-22T23:11:36.492603Z"
    },
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "# 词集的长度\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# 嵌入的维度\n",
    "embedding_dim = 256\n",
    "\n",
    "# RNN 的单元数量\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:36.498222Z",
     "iopub.status.busy": "2020-09-22T23:11:36.497537Z",
     "iopub.status.idle": "2020-09-22T23:11:36.499471Z",
     "shell.execute_reply": "2020-09-22T23:11:36.499955Z"
    },
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:36.514080Z",
     "iopub.status.busy": "2020-09-22T23:11:36.503336Z",
     "iopub.status.idle": "2020-09-22T23:11:36.729450Z",
     "shell.execute_reply": "2020-09-22T23:11:36.729890Z"
    },
    "id": "wwsrpOik5zhv"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkA5upJIJ7W7"
   },
   "source": [
    "对于每个字符，模型会查找嵌入，把嵌入当作输入运行 GRU 一个时间步，并用密集层生成逻辑回归 （logits），预测下一个字符的对数可能性。\n",
    "![数据在模型中传输的示意图](https://github.com/littlebeanbean7/docs/blob/master/site/en/tutorials/text/images/text_generation_training.png?raw=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ubPo0_9Prjb"
   },
   "source": [
    "## 试试这个模型\n",
    "\n",
    "现在运行这个模型，看看它是否按预期运行。\n",
    "\n",
    "首先检查输出的形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:36.735344Z",
     "iopub.status.busy": "2020-09-22T23:11:36.734683Z",
     "iopub.status.idle": "2020-09-22T23:11:39.311193Z",
     "shell.execute_reply": "2020-09-22T23:11:39.310675Z"
    },
    "id": "C-_70kKAPrPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 4024) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6NzLBi4VM4o"
   },
   "source": [
    "在上面的例子中，输入的序列长度为 `100`， 但是这个模型可以在任何长度的输入上运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:39.317768Z",
     "iopub.status.busy": "2020-09-22T23:11:39.317134Z",
     "iopub.status.idle": "2020-09-22T23:11:39.320153Z",
     "shell.execute_reply": "2020-09-22T23:11:39.320575Z"
    },
    "id": "vPGmAAXmVLGC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           1030144   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 4024)          4124600   \n",
      "=================================================================\n",
      "Total params: 9,093,048\n",
      "Trainable params: 9,093,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwv0gEkURfx1"
   },
   "source": [
    "为了获得模型的实际预测，我们需要从输出分布中抽样，以获得实际的字符索引。这个分布是根据对字符集的逻辑回归定义的。\n",
    "\n",
    "请注意：从这个分布中 _抽样_ 很重要，因为取分布的 _最大值自变量点集（argmax）_ 很容易使模型卡在循环中。\n",
    "\n",
    "试试这个批次中的第一个样本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:39.325173Z",
     "iopub.status.busy": "2020-09-22T23:11:39.324482Z",
     "iopub.status.idle": "2020-09-22T23:11:39.327727Z",
     "shell.execute_reply": "2020-09-22T23:11:39.328135Z"
    },
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QM1Vbxs_URw5"
   },
   "source": [
    "这使我们得到每个时间步预测的下一个字符的索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:39.332924Z",
     "iopub.status.busy": "2020-09-22T23:11:39.332257Z",
     "iopub.status.idle": "2020-09-22T23:11:39.334697Z",
     "shell.execute_reply": "2020-09-22T23:11:39.335191Z"
    },
    "id": "YqFMUQc_UFgM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3471, 1880, 2762, 2181, 2879,  291, 1909, 3563,  720, 3727, 2660,\n",
       "       1955, 3570, 2812, 2067,  219, 2809, 3261,  240,  629, 2288,  290,\n",
       "        530, 1633, 3155, 2503, 1154, 2683, 1134, 3916,  964,  148, 1907,\n",
       "       1697, 1833, 2467,  824, 1345, 2365, 3207, 2214,  499, 3549, 1189,\n",
       "       1880, 2606, 2786, 3566,  135,  758, 3673, 2967, 3802, 2593, 2258,\n",
       "       2119, 1040, 1259,  414, 2931, 1928, 3533, 3031,  146, 1960,  845,\n",
       "       3168, 3586, 1467, 3160, 1141,  130, 3220, 2671, 2541, 1392, 1979,\n",
       "       2947, 1641, 3458, 3022, 2788, 1725, 2411,   93, 3464, 2039, 3082,\n",
       "       2163, 2687,  788, 2199, 1039, 1568,  157,  251, 3604, 3224, 1304,\n",
       "       2806])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfLtsP3mUhCG"
   },
   "source": [
    "解码它们，以查看此未经训练的模型预测的文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:39.339800Z",
     "iopub.status.busy": "2020-09-22T23:11:39.339157Z",
     "iopub.status.idle": "2020-09-22T23:11:39.343122Z",
     "shell.execute_reply": "2020-09-22T23:11:39.342579Z"
    },
    "id": "xWcFwPwLSo05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " '問破黃巾將士索金帛，不從者奏罷職。皇甫嵩、朱俊皆不肯與，趙忠等俱奏罷其官。帝又封趙忠等為車騎將軍，張讓等十三人皆封列侯。朝政愈壞，人民嗟怨。於是長沙賊區星作亂；漁陽張舉、張純反：舉稱天子，純稱大將軍。'\n",
      "\n",
      "Next Char Predictions: \n",
      " '遷洩肢珪茅凝涼量妃雝繚源釭膽煎傾膠費儲堆癖凜啞架誨竿惑罕悄鬧幟侄涪楊汪穆寅捽瞭譙璧咫醜慓洩絮脯釘何媒降藺頸紳異牢彘扈卸蒼淵酉術佻溢寵諛銜敘調悖低讒纏簞搬滸蕤柔達蠢腐樊祖仁遣灘西獲置孰瑛彎暹侵克鍋谷拗膚'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCbHQHiaa4Ic"
   },
   "source": [
    "此时，这个问题可以被视为一个标准的分类问题：给定先前的 RNN 状态和这一时间步的输入，预测下一个字符的类别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trpqTWyvk0nr"
   },
   "source": [
    "### 添加优化器和损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAjbjY03eiQ4"
   },
   "source": [
    "标准的 `tf.keras.losses.sparse_categorical_crossentropy` 损失函数在这里适用，因为它被应用于预测的最后一个维度。\n",
    "\n",
    "因为我们的模型返回逻辑回归，所以我们需要设定命令行参数 `from_logits`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:39.348288Z",
     "iopub.status.busy": "2020-09-22T23:11:39.347662Z",
     "iopub.status.idle": "2020-09-22T23:11:39.352837Z",
     "shell.execute_reply": "2020-09-22T23:11:39.353302Z"
    },
    "id": "4HrXTACTdzY-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 4024)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       8.300052\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeOXriLcymww"
   },
   "source": [
    "使用 `tf.keras.Model.compile` 方法配置训练步骤。我们将使用 `tf.keras.optimizers.Adam` 并采用默认参数，以及损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:39.366019Z",
     "iopub.status.busy": "2020-09-22T23:11:39.365311Z",
     "iopub.status.idle": "2020-09-22T23:11:39.372761Z",
     "shell.execute_reply": "2020-09-22T23:11:39.373192Z"
    },
    "id": "DDl1_Een6rL0"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieSJdchZggUj"
   },
   "source": [
    "### 配置检查点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6XBUUavgF56"
   },
   "source": [
    "使用 `tf.keras.callbacks.ModelCheckpoint` 来确保训练过程中保存检查点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:39.378017Z",
     "iopub.status.busy": "2020-09-22T23:11:39.377416Z",
     "iopub.status.idle": "2020-09-22T23:11:39.379758Z",
     "shell.execute_reply": "2020-09-22T23:11:39.379184Z"
    },
    "id": "W6fWTriUZP-n"
   },
   "outputs": [],
   "source": [
    "# 检查点保存至的目录\n",
    "checkpoint_dir = './training_checkpoints_2'\n",
    "\n",
    "# 检查点的文件名\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ky3F_BhgkTW"
   },
   "source": [
    "### 执行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxdOA-rgyGvs"
   },
   "source": [
    "为保持训练时间合理，使用 10 个周期来训练模型。在 Colab 中，将运行时设置为 GPU 以加速训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:39.383670Z",
     "iopub.status.busy": "2020-09-22T23:11:39.383052Z",
     "iopub.status.idle": "2020-09-22T23:11:39.385300Z",
     "shell.execute_reply": "2020-09-22T23:11:39.384725Z"
    },
    "id": "7yGBE2zxMMHs"
   },
   "outputs": [],
   "source": [
    "EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:11:39.389181Z",
     "iopub.status.busy": "2020-09-22T23:11:39.388583Z",
     "iopub.status.idle": "2020-09-22T23:12:35.857088Z",
     "shell.execute_reply": "2020-09-22T23:12:35.857510Z"
    },
    "id": "UK-hmKjYVoll"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "96/96 [==============================] - 534s 6s/step - loss: 6.1924\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 508s 5s/step - loss: 5.0730\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 521s 5s/step - loss: 4.6017\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 456s 5s/step - loss: 4.2920\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 272s 3s/step - loss: 4.0607\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 409s 4s/step - loss: 3.8660\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 506s 5s/step - loss: 3.6860\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 506s 5s/step - loss: 3.5192\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 507s 5s/step - loss: 3.3582\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 503s 5s/step - loss: 3.1994\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## 生成文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIPcXllKjkdr"
   },
   "source": [
    "### 恢复最新的检查点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyeYRiuVjodY"
   },
   "source": [
    "为保持此次预测步骤简单，将批大小设定为 1。\n",
    "\n",
    "由于 RNN 状态从时间步传递到时间步的方式，模型建立好之后只接受固定的批大小。\n",
    "\n",
    "若要使用不同的 `batch_size` 来运行模型，我们需要重建模型并从检查点中恢复权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:12:35.862572Z",
     "iopub.status.busy": "2020-09-22T23:12:35.861664Z",
     "iopub.status.idle": "2020-09-22T23:12:35.866147Z",
     "shell.execute_reply": "2020-09-22T23:12:35.866575Z"
    },
    "id": "zk2WJ2-XjkGz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints_2/ckpt_10'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:12:35.877576Z",
     "iopub.status.busy": "2020-09-22T23:12:35.876885Z",
     "iopub.status.idle": "2020-09-22T23:12:36.093523Z",
     "shell.execute_reply": "2020-09-22T23:12:36.093984Z"
    },
    "id": "LycQ-ot_jjyu"
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:12:36.099320Z",
     "iopub.status.busy": "2020-09-22T23:12:36.098648Z",
     "iopub.status.idle": "2020-09-22T23:12:36.102286Z",
     "shell.execute_reply": "2020-09-22T23:12:36.101721Z"
    },
    "id": "71xa6jnYVrAN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            1030144   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 4024)           4124600   \n",
      "=================================================================\n",
      "Total params: 9,093,048\n",
      "Trainable params: 9,093,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjGz1tDkzf-u"
   },
   "source": [
    "### 预测循环\n",
    "\n",
    "下面的代码块生成文本：\n",
    "\n",
    "* 首先设置起始字符串，初始化 RNN 状态并设置要生成的字符个数。\n",
    "\n",
    "* 用起始字符串和 RNN 状态，获取下一个字符的预测分布。\n",
    "\n",
    "* 然后，用分类分布计算预测字符的索引。把这个预测字符当作模型的下一个输入。\n",
    "\n",
    "* 模型返回的 RNN 状态被输送回模型。现在，模型有更多上下文可以学习，而非只有一个字符。在预测出下一个字符后，更改过的 RNN 状态被再次输送回模型。模型就是这样，通过不断从前面预测的字符获得更多上下文，进行学习。\n",
    "\n",
    "![为生成文本，模型的输出被输送回模型作为输入](https://github.com/littlebeanbean7/docs/blob/master/site/en/tutorials/text/images/text_generation_sampling.png?raw=1)\n",
    "\n",
    "查看生成的文本，你会发现这个模型知道什么时候使用大写字母，什么时候分段，而且模仿出了莎士比亚式的词汇。由于训练的周期小，模型尚未学会生成连贯的句子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:12:36.109457Z",
     "iopub.status.busy": "2020-09-22T23:12:36.108816Z",
     "iopub.status.idle": "2020-09-22T23:12:36.111119Z",
     "shell.execute_reply": "2020-09-22T23:12:36.110588Z"
    },
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # 评估步骤（用学习过的模型生成文本）\n",
    "\n",
    "  # 要生成的字符个数\n",
    "  num_generate = 1000\n",
    "\n",
    "  # 将起始字符串转换为数字（向量化）\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # 空字符串用于存储结果\n",
    "  text_generated = []\n",
    "\n",
    "  # 低温度会生成更可预测的文本\n",
    "  # 较高温度会生成更令人惊讶的文本\n",
    "  # 可以通过试验以找到最好的设定\n",
    "  temperature = 1.0\n",
    "\n",
    "  # 这里批大小为 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # 删除批次的维度\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # 用分类分布预测模型返回的字符\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # 把预测字符和前面的隐藏状态一起传递给模型作为下一个输入\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:12:36.114992Z",
     "iopub.status.busy": "2020-09-22T23:12:36.114300Z",
     "iopub.status.idle": "2020-09-22T23:12:40.032351Z",
     "shell.execute_reply": "2020-09-22T23:12:40.031654Z"
    },
    "id": "ktovv0RFhrkn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "三國 澤欲行此二\n",
      "　　朱將，自畫良、青阜二人也。來天明召入川中，其掠可宜厚，不久已失矣。「操曰：」討賊之勢，雖毀書，豈容朕孤相惶乎？今使君背義，安敢猶信！「霸又三說本部將士真先去，以為錢糧。趙雲果然鎮南應，深不入境，奔周倉恐眾，百萬發兵而入。懿曰：「某素知兵甚是此；不為將軍相助公瑾，先忘使君，遂立盟於宮醉之間，議論其故，乃聚眾商議，不分兵敗，引數千輛甲水奔浮橋；諸軍在帳中曰：「此四將不保也！」喝令左右推出斬之。眾諸侯悚然。左問楊奉曰：「孔明破山之時，如不孟達；今已失了，軍士不得勝之，意恐未、，非汝二日之盟，只待交鋒，故卻先滅元宵，盡責趙雲、幽州、馬遵英雄將軍法，穩取瀘水之旌。能使人應雖為虎侯，亦是吳侯將趙子龍單、涼等眾謀士人皆厚信之情，恐玄德不定。今曹丕已平拒荊州，可治撫若袁紹，若擊之，必須兩州，猶漢朝廷，若遣一人，使其縛之；其天甚受。長之寄賢，以賓朝廷納降；至輔鄭首，遷都國舅，仰承無名；但等深：生真義於楚矣！「嗣曰：」眾幼間言，便伏皇體，包屨子），拒承正平天病。畢董炎奸虐，糜輅也極善。趙雲出馬即與焦共交戰。斗陣數十餘里，曹操屯住城門，中央梁水打下，一騎刺斜裡到。兩陣對圓，忠亦喝楊松曰：「此非大夫人曾告弟之甥。」荀攸曰：「汝等豈敢抗丞相敵乎？吾見父宗詭之，今若為前攻取長親，早下遠涉而入帳，飲了酒數十杯游著畫清。次日，諸將請樂綝極頌；吳將奐與祿共載：幼和二人，專為貪腹將吏。帝懼之所，不能密意，恐死無怨耳。怎生辨殺之體？必須誤來決計。「\n",
      "　　\n",
      "　　施禮畢，阜奏曰：「魏將魏兵甚當城地，不可輕敵。且可當全身只謹從山前去。「王平曰：」敗軍必須擒德。若守潼屍，破劉萇之過矣；隔山破之，必有準備。功勞我築了糧道殺貴，如何？』乃大丈夫，以勵禁愆；我行不服，法正說後也。若不可言，則共攻蜀兵也。」懿問其計。正是：強弱後革未息，供死一旦田。米知勝烈常，文無不學健郡，妙好大書，實與同謀安同諸公州郡。『等不可以為先鋒。」\n",
      "　　\n",
      "　　孔明諫曰：「周瑜績喪甚愛人，幸無他限，先遣人敢來求戰未遲。」次曰：「黃公覆虎艱樹，黃三江夏，如雨而降，此必慢之。」\n",
      "　　\n",
      "　　二次將眾官捧畢，忽然報鄧艾，後人報知魏王，乃召岑威、金紀商議殺出曹爽以為己連。\n",
      "　　\n",
      "　　後槽料知事名，急召回去。懿曰：「吾算度已無一物，今早有細射倒之狀。瓚入帳中見罪，驚問是誰。」漢中王曰：「目恐袁坐初軟多少客，未知，超生不能賢\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"三國 \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AM2Uma_-yVIq"
   },
   "source": [
    "若想改进结果，最简单的方式是延长训练时间 （试试 `EPOCHS=30`）。\n",
    "\n",
    "你还可以试验使用不同的起始字符串，或者尝试增加另一个 RNN 层以提高模型的准确率，亦或调整温度参数以生成更多或者更少的随机预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4QwTjAM6A2O"
   },
   "source": [
    "## 高级：自定义训练\n",
    "\n",
    "上面的训练步骤简单，但是能控制的地方不多。\n",
    "\n",
    "至此，你已经知道如何手动运行模型。现在，让我们打开训练循环，并自己实现它。这是一些任务的起点，例如实现 _课程学习_ 以帮助稳定模型的开环输出。\n",
    "\n",
    "你将使用 `tf.GradientTape` 跟踪梯度。关于此方法的更多信息请参阅 [eager execution 指南](https://tensorflow.google.cn/guide/eager)。\n",
    "\n",
    "步骤如下：\n",
    "\n",
    "* 首先，初始化 RNN 状态，使用 `tf.keras.Model.reset_states` 方法。\n",
    "\n",
    "* 然后，迭代数据集（逐批次）并计算每次迭代对应的 *预测*。\n",
    "\n",
    "* 打开一个 `tf.GradientTape` 并计算该上下文时的预测和损失。\n",
    "\n",
    "* 使用 `tf.GradientTape.grads` 方法，计算当前模型变量情况下的损失梯度。\n",
    "\n",
    "* 最后，使用优化器的 `tf.train.Optimizer.apply_gradients` 方法向下迈出一步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:12:40.043917Z",
     "iopub.status.busy": "2020-09-22T23:12:40.043269Z",
     "iopub.status.idle": "2020-09-22T23:12:40.256438Z",
     "shell.execute_reply": "2020-09-22T23:12:40.256958Z"
    },
    "id": "_XAm7eCoKULT"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:12:40.261479Z",
     "iopub.status.busy": "2020-09-22T23:12:40.260761Z",
     "iopub.status.idle": "2020-09-22T23:12:40.263320Z",
     "shell.execute_reply": "2020-09-22T23:12:40.262704Z"
    },
    "id": "qUKhnZtMVpoJ"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-22T23:12:40.269326Z",
     "iopub.status.busy": "2020-09-22T23:12:40.268498Z",
     "iopub.status.idle": "2020-09-22T23:12:40.271298Z",
     "shell.execute_reply": "2020-09-22T23:12:40.270709Z"
    },
    "id": "b4kH1o0leVIp"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, target):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(inp)\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            target, predictions, from_logits=True))\n",
    "  grads = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "d4tSNwymzf-q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 3.0915253162384033\n",
      "Epoch 1 Loss 3.1516\n",
      "Time taken for 1 epoch 265.5058150291443 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.847195625305176\n",
      "Epoch 2 Loss 3.0645\n",
      "Time taken for 1 epoch 267.25120878219604 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.643286943435669\n",
      "Epoch 3 Loss 2.7711\n",
      "Time taken for 1 epoch 271.30711460113525 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 2.538961887359619\n",
      "Epoch 4 Loss 2.7476\n",
      "Time taken for 1 epoch 269.3122022151947 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 2.295781373977661\n",
      "Epoch 5 Loss 2.5371\n",
      "Time taken for 1 epoch 265.39928245544434 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 2.209660291671753\n",
      "Epoch 6 Loss 2.4216\n",
      "Time taken for 1 epoch 265.9973375797272 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 2.0382533073425293\n",
      "Epoch 7 Loss 2.3117\n",
      "Time taken for 1 epoch 266.3118257522583 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.892895221710205\n",
      "Epoch 8 Loss 2.0831\n",
      "Time taken for 1 epoch 265.13202118873596 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.7366843223571777\n",
      "Epoch 9 Loss 1.9990\n",
      "Time taken for 1 epoch 263.672646522522 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.7016878128051758\n",
      "Epoch 10 Loss 1.9041\n",
      "Time taken for 1 epoch 263.24040031433105 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练步骤\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  # 在每个训练周期开始时，初始化隐藏状态\n",
    "  # 隐藏状态最初为 None\n",
    "  hidden = model.reset_states()\n",
    "\n",
    "  for (batch_n, (inp, target)) in enumerate(dataset):\n",
    "    loss = train_step(inp, target)\n",
    "\n",
    "    if batch_n % 100 == 0:\n",
    "      template = 'Epoch {} Batch {} Loss {}'\n",
    "      print(template.format(epoch+1, batch_n, loss))\n",
    "\n",
    "  # 每 5 个训练周期，保存（检查点）1 次模型\n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
    "\n",
    "  print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
    "  print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "\n",
    "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (64, None, 256)           1030144   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (64, None, 4024)          4124600   \n",
      "=================================================================\n",
      "Total params: 9,093,048\n",
      "Trainable params: 9,093,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints_2/ckpt_9'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model_2.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model_2.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (1, None, 256)            1030144   \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (1, None, 4024)           4124600   \n",
      "=================================================================\n",
      "Total params: 9,093,048\n",
      "Trainable params: 9,093,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "三國 第056回　商議退兵雪，楊彪軍屯於陽興，將淳於丹往來，時苟免連住，不想赤幘，人死者無數。袁紹已知孔明，自賓之欲取西川。往與何主公董後園一句正商議。公瑾舊歲在水中，無此可知孔明昨因星夜墜地，明名童子，夜至府中所管燈著，皆在御林之下，諸葛亮自走，灌上可騎在米倉城內：因此委勝，亦不可及也。宜宜自效良策，實不進心。萬死一辱，使君力盡存薦。望東建一\n",
      "　　鄉，去三十餘里，正遇選五十番；蠻兵至，乃一群，猶是與魏主否？」眾視之，乃夏侯淵、馬岱、張郃、王封守把各處隘口，把火燒飛，一齊都放起兵來，放火急回，奪路而走。忽然伏路而走，延大路殺來，曹兵大亂，魏軍四散逃走，張郃在後，各自收兵。\n",
      "　　\n",
      "　　卻說玄德曰：「果都是也。\n",
      "　　二人先學所相，指山野而走。雲長急救了一\n",
      "　　方，船上傍不遠矣。閒人見之人，多有少勞，不可錯憂！」子服曰：「君子遇何高見？」彰戰不三合，被雲一槍刺中面；一將踴奮勇冠，引一小卒，用拖索十餘級，用武二十七子，駕小車曹和，入長安。真英雄也！」於是令休憂。劉表、劉表，杜預理密議，教近臣討之。丁奉表藏先往　\n",
      "　　\n",
      "　　\n",
      "　　\n",
      "　　卻說當夜二更正江東，聞使雲長提兵於江陵，又令張遼保護。趙雲、文聘、劉瑰、梁虔守把關張，以拒曹操糧草，拍雨渡河，非敵者不曾雙；馬蹄死，吾一軍擁臨陣前妻去，休慌驚走。崔諒見之，提戟橫刀而來，大叫：「丞相在軍中一處射耳。吾頭所以性命，蓋子所恨不安也。「遂設宴款待費禕.飲宴密詔，引兵回官陽平原，大賞三軍。\n",
      "　　張任是比彝陵人奔回葛陂，大半軍被蜀兵奪了荊州，回報曹睿。魏兵自回\n",
      "　　人引兵入南進，截路往塵頭息；殺彼首者，因欲堅守，乃彈威教將軍斷雲，也不容矣。」使人去內，百官皆歸求葬。操指其問曰：「汝言老將遠，吾在後時，何故錯耶？」王答曰：「有病車之勇，不亞一載，豈敬若錯？兄欲自縊成都，與天幸作當！\n",
      "　　持了王，各聞得了官後，獻首數禮，具說呂布轅門都入宮，共了其子，設一宴於會稽扶上殿而歎曰：「害我者無去其厄！」回顧左右將過，來見館驛，細言不答。玄德訴說東南名福，相勸而不感；今魯事為太州，怎能破賊？」當晚而去。昭又將白旗保駕一半，循河為一\n",
      "　　川，慌辭漢中王。周平大怒，使雲長守護出。維令雲長引軍救住。趙雲引一千餘人，自出魏來，交馬只一合，高定引兩枝兵來，八面殺人；盛德甚是忠心，已知魏國之眾，來救謝天下罪。」漢中王曰：「陛下沮掌社稷，實欲討賊\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_2, start_string=u\"三國 \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
