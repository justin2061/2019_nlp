{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 38.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/cf/7089b87fdae8f47be81ce8e2e6377b321805c4648f2eb12fbd2987388dac/sentencepiece-0.1.83-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 40.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting boto3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/60/40b189b276d65220853af1b4088ded17598e7417feebbcefb3c580eef94e/boto3-1.10.33-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 46.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
      "\u001b[K     |████████████████████████████████| 860kB 44.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/1d/13cc7d174cd2d05808abac3f5fb37433e30c4cd93b152d2a9c09c926d7e8/regex-2019.11.1.tar.gz (669kB)\n",
      "\u001b[K     |████████████████████████████████| 675kB 40.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pytorch-transformers) (1.17.3)\n",
      "Collecting torch>=1.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/34/2107f342d4493b7107a600ee16005b2870b5a0a5a165bdf5c5e7168a16a6/torch-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (734.6MB)\n",
      "\u001b[K     |████████████████████████████████| 734.6MB 49kB/s s eta 0:00:01    |██▏                             | 49.8MB 43.8MB/s eta 0:00:16\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pytorch-transformers) (4.37.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from pytorch-transformers) (2.22.0)\n",
      "Collecting botocore<1.14.0,>=1.13.33\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/00/475c3f9f4b1064c6b7ae4f07a485939df03e6412e025912e399d27d9f16f/botocore-1.13.33-py2.py3-none-any.whl (5.8MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8MB 35.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.3.0,>=0.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 18.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->pytorch-transformers) (1.13.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->pytorch-transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->pytorch-transformers) (0.14.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch-transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch-transformers) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch-transformers) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch-transformers) (3.0.4)\n",
      "Collecting python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 44.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docutils<0.16,>=0.10\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
      "\u001b[K     |████████████████████████████████| 552kB 42.6MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: sacremoses, regex\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp37-none-any.whl size=883999 sha256=da37734307b3da1f36851e1746c2b2664a6073baf1285a5026d4438faf42d1c3\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for regex: filename=regex-2019.11.1-cp37-cp37m-linux_x86_64.whl size=616444 sha256=2c9b4aaedf7af0f5b4ac6d12560949e68255abb8360a077f40eba1dc5a93b3eb\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/5c/c6/c1/0bc8d16ea38c44536a82dd1bec665996e5af37489fa88826b6\n",
      "Successfully built sacremoses regex\n",
      "Installing collected packages: sentencepiece, python-dateutil, jmespath, docutils, botocore, s3transfer, boto3, sacremoses, regex, torch, pytorch-transformers\n",
      "  Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "Successfully installed boto3-1.10.33 botocore-1.13.33 docutils-0.15.2 jmespath-0.9.4 python-dateutil-2.8.0 pytorch-transformers-1.2.0 regex-2019.11.1 s3transfer-0.2.1 sacremoses-0.0.35 sentencepiece-0.1.83 torch-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.37.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsnooper\n",
      "  Downloading https://files.pythonhosted.org/packages/33/52/91ad263db398cf1fb5689c562bab82d35184501dc7ad62805d535fd27fa7/TorchSnooper-0.7.1-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchsnooper) (1.17.3)\n",
      "Collecting pysnooper>=0.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/e8/fd8cf0225d2bb57bce15fc9914d4cfe9dd7008c99d058bf511028df7472c/PySnooper-0.3.0-py2.py3-none-any.whl\n",
      "Installing collected packages: pysnooper, torchsnooper\n",
      "Successfully installed pysnooper-0.3.0 torchsnooper-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsnooper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-05 09:23:30--  https://docs.google.com/uc?export=download&confirm=KDY2&id=1Z8WdVYgBj01BHU4syjlY9qj3KBfEFP2D\n",
      "Resolving docs.google.com (docs.google.com)... 172.217.31.174, 2404:6800:4004:80c::200e\n",
      "Connecting to docs.google.com (docs.google.com)|172.217.31.174|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-0g-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/cdcf75cdl5gg57br0vess68goeonrgc4/1575532800000/08564091608614806726/*/1Z8WdVYgBj01BHU4syjlY9qj3KBfEFP2D?e=download [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2019-12-05 09:23:30--  https://doc-0g-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/cdcf75cdl5gg57br0vess68goeonrgc4/1575532800000/08564091608614806726/*/1Z8WdVYgBj01BHU4syjlY9qj3KBfEFP2D?e=download\n",
      "Resolving doc-0g-38-docs.googleusercontent.com (doc-0g-38-docs.googleusercontent.com)... 172.217.25.225, 2404:6800:4004:81b::2001\n",
      "Connecting to doc-0g-38-docs.googleusercontent.com (doc-0g-38-docs.googleusercontent.com)|172.217.25.225|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘10layers_12heads_1024len_768embd_full_corpus_16bsize.zip’\n",
      "\n",
      "10layers_12heads_10     [                <=> ] 289.96M  83.4MB/s    in 3.6s    \n",
      "\n",
      "2019-12-05 09:23:34 (79.6 MB/s) - ‘10layers_12heads_1024len_768embd_full_corpus_16bsize.zip’ saved [304045848]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Z8WdVYgBj01BHU4syjlY9qj3KBfEFP2D' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1Z8WdVYgBj01BHU4syjlY9qj3KBfEFP2D\" -O 10layers_12heads_1024len_768embd_full_corpus_16bsize.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_REPO = \"GPT2-Chinese\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'GPT2-Chinese'...\n",
      "remote: Enumerating objects: 184, done.\u001b[K\n",
      "remote: Total 184 (delta 0), reused 0 (delta 0), pack-reused 184\u001b[K\n",
      "Receiving objects: 100% (184/184), 13.40 MiB | 8.28 MiB/s, done.\n",
      "Resolving deltas: 100% (88/88), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf {GITHUB_REPO}\n",
    "!git clone https://github.com/Morizeyao/{GITHUB_REPO}.git {GITHUB_REPO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not GITHUB_REPO in sys.path:\n",
    "    sys.path += [GITHUB_REPO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (2019.11.1)\n",
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/1a/364556102943cacde1ee00fdcae3b1615b39e52649eddbf54953e5b144c9/transformers-2.2.1-py3-none-any.whl (364kB)\n",
      "\u001b[K     |████████████████████████████████| 368kB 34.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.35)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from transformers) (4.37.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from transformers) (0.1.83)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.17.3)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from transformers) (2019.11.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.10.33)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.13.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.25.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from boto3->transformers) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.33 in /opt/conda/lib/python3.7/site-packages (from boto3->transformers) (1.13.33)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.33->boto3->transformers) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.33->boto3->transformers) (0.15.2)\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!test -d bertviz_repo || git clone https://github.com/jessevig/bertviz bertviz_repo\n",
    "if not 'bertviz_repo' in sys.path:\n",
    "    sys.path += ['bertviz_repo']\n",
    "!pip install regex\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import textwrap\n",
    "import torchsnooper\n",
    "import pytorch_transformers\n",
    "import torch.nn.functional as F\n",
    "from tqdm import trange\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = '10layers_12heads_1024len_768embd_full_corpus_16bsize'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  10layers_12heads_1024len_768embd_full_corpus_16bsize.zip\n",
      "  inflating: home/ec2-user/SageMaker/tmp/GPT2-Chinese/model/10layers_12heads_1024len_768embd_full_corpus_16bsize/config.json  \n",
      "  inflating: home/ec2-user/SageMaker/tmp/GPT2-Chinese/model/10layers_12heads_1024len_768embd_full_corpus_16bsize/pytorch_model.bin  \n",
      "  inflating: home/ec2-user/SageMaker/tmp/GPT2-Chinese/cache/vocab_small.txt  \n"
     ]
    }
   ],
   "source": [
    "!unzip {pretrained_model}.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_base_path = 'home/ec2-user/SageMaker/tmp/GPT2-Chinese'\n",
    "config_file = 'config.json'\n",
    "model_ckpt = \"pytorch_model.bin\"\n",
    "vocab_file = \"vocab_small.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'pytorch_model.bin': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm {config_file} {model_ckpt} {vocab_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv {sagemaker_base_path}/model/{pretrained_model}/{config_file} {config_file}\n",
    "!mv {sagemaker_base_path}/model/{pretrained_model}/{model_ckpt} {model_ckpt}\n",
    "!mv {sagemaker_base_path}/cache/{vocab_file} {vocab_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizations import tokenization_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = pytorch_transformers.GPT2Config.from_json_file(config_file)\n",
    "config.output_attentions = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pytorch_transformers.GPT2LMHeadModel.from_pretrained(\".\", config=config)\n",
    "tokenizer = tokenization_bert.BertTokenizer(vocab_file=vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(13317, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=13317, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_word(word):\n",
    "    for item in list(word):\n",
    "        if item not in 'qwertyuiopasdfghjklzxcvbnm':\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (vocabulary size)\n",
    "            top_k > 0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p > 0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "        From: https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317\n",
    "    \"\"\"\n",
    "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_sample_sequence(model,context,length,temperature=1, top_k=0, top_p=0.0,device='cpu'):\n",
    "    inputs = torch.LongTensor(context).view(1, -1).to(device)\n",
    "    if len(context) > 1:\n",
    "        _, past = model(inputs[:, :-1], None)[:2]\n",
    "        prev = inputs[:, -1].view(1, -1)\n",
    "    else:\n",
    "        past = None\n",
    "        prev = inputs\n",
    "    generate = [] + context\n",
    "    with torch.no_grad():\n",
    "        for i in trange(length):\n",
    "            output = model(prev, past=past)\n",
    "            output, past = output[:2]\n",
    "            output = output[-1].squeeze(0) / temperature\n",
    "            filtered_logits = top_k_top_p_filtering(output, top_k=top_k, top_p=top_p)\n",
    "            next_token = torch.multinomial(torch.softmax(filtered_logits, dim=-1), num_samples=1)\n",
    "            \n",
    "            # redraw if [UNK]\n",
    "            if next_token.unsqueeze(0) != 100:\n",
    "                generate.append(next_token.item())\n",
    "                prev = next_token.view(1, 1)\n",
    "\n",
    "    return generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(context, generated_text, novel_name='', algorithm=''):\n",
    "    if generated_text[-1] != '。':\n",
    "        if generated_text[-1] == '，':\n",
    "            generated_text= generated_text[:-1]\n",
    "        generated_text += ' ...'\n",
    "    \n",
    "    html = \"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "    <style>\n",
    "    * {\n",
    "      box-sizing: border-box;\n",
    "    }\n",
    "\n",
    "    /* Create two unequal columns that floats next to each other */\n",
    "    .column {\n",
    "      float: left;\n",
    "      padding: 10px;\n",
    "    }\n",
    "\n",
    "    .left {\n",
    "      width: 20%;\n",
    "    }\n",
    "\n",
    "    .right {\n",
    "      width: 80%;\n",
    "    }\n",
    "\n",
    "    /* Clear floats after the columns */\n",
    "    .row:after {\n",
    "      content: \"\";\n",
    "      display: table;\n",
    "      clear: both;\n",
    "    }\n",
    "    </style>\n",
    "    </head>\n",
    "    <body>\n",
    "\n",
    "    <div style=\"background-color:#FFFFF0 !important\">\n",
    "        <div class=\"row\">\n",
    "          <div class=\"column left\">\n",
    "            <h3 style=\"color: #bfbaba;text-align:center\">\n",
    "                GPT-2看了這個標題的內容：\n",
    "                novel_name\n",
    "                \n",
    "            </h2>\n",
    "          </div>\n",
    "          <div class=\"column right\">\n",
    "            <h3 style=\"color: #708090;line-height: 1.5\">context</h3>\n",
    "          </div>\n",
    "        </div>\n",
    "\n",
    "        <hr/>\n",
    "\n",
    "        <div class=\"row\">\n",
    "          <div class=\"column left\">\n",
    "            <h3 style=\"color: #00477D;text-align:center\">\n",
    "                algorithm\n",
    "                GPT2說...\n",
    "            </h2>\n",
    "          </div>\n",
    "          <div class=\"column right\">\n",
    "            <h3 style=\"color: #006374;line-height: 1.5\">generated_text</h3>\n",
    "\n",
    "          </div>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    </body>\n",
    "    </html>\n",
    "\n",
    "\n",
    "    \"\"\".replace('context', context).replace('generated_text', generated_text).replace(\"novel_name\", f'《{novel_name}》<br/>')\n",
    "    \n",
    "    if not algorithm:\n",
    "        html = html.replace(\"algorithm\", \"\")\n",
    "    else:\n",
    "        html = html.replace(\"algorithm\", f'{algorithm}<br/>')\n",
    "    \n",
    "    \n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(context, topk, topp, temperature, device, line_len=40, novel_name=''):\n",
    "    context_tokens = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(context))\n",
    "        \n",
    "    # auto-regressive\n",
    "    out = fast_sample_sequence(\n",
    "        model=model, length=length,\n",
    "        context=context_tokens,\n",
    "        temperature=temperature, top_k=topk, top_p=topp, device=device\n",
    "    )\n",
    "\n",
    "    # rendering\n",
    "    tokens = tokenizer.convert_ids_to_tokens(out)\n",
    "\n",
    "    for i, item in enumerate(tokens):\n",
    "        if item == '[MASK]':\n",
    "            tokens[i] = ''\n",
    "        if item == '[CLS]' or item == '[SEP]':\n",
    "            tokens[i] = '\\n'\n",
    "    \n",
    "    generated_text = ''.join(tokens).strip().replace(context, '')\n",
    "    html = get_html(context, generated_text, novel_name=novel_name)\n",
    "    \n",
    "    return html, generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ title 生成參數、Decoding 策略設定（生成溫度等）\n",
    "nsamples = 1\n",
    "batch_size = 1\n",
    "length = model.config.n_ctx // 2\n",
    "\n",
    "topk = 30\n",
    "topp = 0\n",
    "temperature = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改變此變數來選擇不同的前文脈絡。當然你也可以自行填加\n",
    "sample_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 飛雪連天射白鹿，笑書神俠倚碧鴛。\n",
    "sampled_contexts =[\n",
    "    ('寶可夢 劍／盾', '任天堂年度大作《寶可夢 劍／盾》正式發表，上市前就備受訓練家們期待，根據寶可夢公司最新公告，首週全球銷售突破  600 萬，打破 Switch 新紀錄，然而玩家社群們卻是負評如潮。'),\n",
    "    ('「Cybertrunk」將於《電馭叛客 2077》登場?', '行事風格向來不按牌理出牌的特斯拉汽車執行長伊隆馬斯克 (Elon Musk) 在上週的發表會上發表了一台造型相當前衛的全新車種－「The Cybertruck」。這台充滿Cyberpunk風格的全新電動車標榜著環保的特性，以及防彈的強化玻璃，即使在發表會上出了點小包，一砸就出現裂痕。然而，即使無法購買這台真車的玩家們，也許有機會在《電馭叛客 2077》中駕駛這台獨特的汽車，奔馳於遊戲中的「夜城」(Night City) 街道。'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sampled_contexts[sample_idx]\n",
    "novel_name, context = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:16<00:00, 30.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    <html>\\n    <head>\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n    <style>\\n    * {\\n      box-sizing: border-box;\\n    }\\n\\n    /* Create two unequal columns that floats next to each other */\\n    .column {\\n      float: left;\\n      padding: 10px;\\n    }\\n\\n    .left {\\n      width: 20%;\\n    }\\n\\n    .right {\\n      width: 80%;\\n    }\\n\\n    /* Clear floats after the columns */\\n    .row:after {\\n      content: \"\";\\n      display: table;\\n      clear: both;\\n    }\\n    </style>\\n    </head>\\n    <body>\\n\\n    <div style=\"background-color:#FFFFF0 !important\">\\n        <div class=\"row\">\\n          <div class=\"column left\">\\n            <h3 style=\"color: #bfbaba;text-align:center\">\\n                GPT-2看了這個標題的內容：\\n                《「Cybertrunk」將於《電馭叛客 2077》登場?》<br/>\\n                \\n            </h2>\\n          </div>\\n          <div class=\"column right\">\\n            <h3 style=\"color: #708090;line-height: 1.5\">行事風格向來不按牌理出牌的特斯拉汽車執行長伊隆馬斯克 (Elon Musk) 在上週的發表會上發表了一台造型相當前衛的全新車種－「The Cybertruck」。這台充滿Cyberpunk風格的全新電動車標榜著環保的特性，以及防彈的強化玻璃，即使在發表會上出了點小包，一砸就出現裂痕。然而，即使無法購買這台真車的玩家們，也許有機會在《電馭叛客 2077》中駕駛這台獨特的汽車，奔馳於遊戲中的「夜城」(Night City) 街道。</h3>\\n          </div>\\n        </div>\\n\\n        <hr/>\\n\\n        <div class=\"row\">\\n          <div class=\"column left\">\\n            <h3 style=\"color: #00477D;text-align:center\">\\n                \\n                GPT2說...\\n            </h2>\\n          </div>\\n          <div class=\"column right\">\\n            <h3 style=\"color: #006374;line-height: 1.5\">行事風格向來不按牌理出牌的特斯拉汽車執行長伊隆馬斯克(el##onmu##sk)在上週的發表會上發表了一台造型相當前衛的全新車種－「thec##y##bert##ru##ck」。這台充滿c##y##ber##pu##nk風格的全新電動車標榜著環保的特性，以及防彈的強化玻璃，即使在發表會上出了點小包，一砸就出現裂痕。然而，即使無法購買這台真車的玩家們，也許有機會在《電馭叛客2077》中駕駛這台獨特的汽車，奔馳於遊戲中的「夜城」(nightcity)街道。\\n精忠之故鰲拜專踢了一團亮，如獲滅跡，當然有人前來投靠，勢道極緩慢，守到天明時，鄰近府的門戶溝稍停，有人推門推門進去。他見進來，當下滿是鹽擔，當下滿滿滿了一副弓箭的大小門坐在凳上，每人手上都是銬，一面團黑漆，穿了一條小門，就是一副弓彈打造得精鋼熟的模樣。\\n廳上眾鹽梟見了這等大聲勢，紛紛鼓掌。安提督府中老兄贊道：「韋香主，你天明，果然有刺客。」余人一聽，都是又驚又喜，又是慚愧。老三道：「這批匪徒大會聚會，你天明日到老來，是不是來了嗎？」韋小寶笑道：「倒不是有點門戶，比之我做戲，這個夢想做戲的會唱戲，太也老是纏夾不牢，沒想要犯罪。這叫做老成，是擺明瞭料得很。」\\n忽聽得廳外有人壓低聲說道：「進來。」諸鹽梟響聲中，一齊擁進，大家跳上桌來，瞧著「賊廝鳥」的模樣，有些手腳都拿著鬼頭刀。大家眼見那些鹽商人平日之事不知聞。\\n韋小寶震於鹽稅甚多，討了些錢鹽稅，弄得本錢生意，十幾只鹽稅一濫，沒多幾便加一錢稅，何必多結幾條人命？突然見有聲音一變，不由得臉上變色，但大吃一驚，這一驚非同小可。韋小寶急忙跳起身來，噗的一聲，坐入房中，從掌櫃台踢了一腳，大叫：「拿酒來，拿酒來！」\\n他一鑽入房中，立即縮頭不見有人，立即縮頭走出，只聽那 ...</h3>\\n\\n          </div>\\n        </div>\\n    </div>\\n\\n    </body>\\n    </html>\\n\\n\\n    '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html, generated_text = generate(context, topk, topp, temperature, device, novel_name=novel_name)\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'行事風格向來不按牌理出牌的特斯拉汽車執行長伊隆馬斯克(el##onmu##sk)在上週的發表會上發表了一台造型相當前衛的全新車種－「thec##y##bert##ru##ck」。這台充滿c##y##ber##pu##nk風格的全新電動車標榜著環保的特性，以及防彈的強化玻璃，即使在發表會上出了點小包，一砸就出現裂痕。然而，即使無法購買這台真車的玩家們，也許有機會在《電馭叛客2077》中駕駛這台獨特的汽車，奔馳於遊戲中的「夜城」(nightcity)街道。\\n精忠之故鰲拜專踢了一團亮，如獲滅跡，當然有人前來投靠，勢道極緩慢，守到天明時，鄰近府的門戶溝稍停，有人推門推門進去。他見進來，當下滿是鹽擔，當下滿滿滿了一副弓箭的大小門坐在凳上，每人手上都是銬，一面團黑漆，穿了一條小門，就是一副弓彈打造得精鋼熟的模樣。\\n廳上眾鹽梟見了這等大聲勢，紛紛鼓掌。安提督府中老兄贊道：「韋香主，你天明，果然有刺客。」余人一聽，都是又驚又喜，又是慚愧。老三道：「這批匪徒大會聚會，你天明日到老來，是不是來了嗎？」韋小寶笑道：「倒不是有點門戶，比之我做戲，這個夢想做戲的會唱戲，太也老是纏夾不牢，沒想要犯罪。這叫做老成，是擺明瞭料得很。」\\n忽聽得廳外有人壓低聲說道：「進來。」諸鹽梟響聲中，一齊擁進，大家跳上桌來，瞧著「賊廝鳥」的模樣，有些手腳都拿著鬼頭刀。大家眼見那些鹽商人平日之事不知聞。\\n韋小寶震於鹽稅甚多，討了些錢鹽稅，弄得本錢生意，十幾只鹽稅一濫，沒多幾便加一錢稅，何必多結幾條人命？突然見有聲音一變，不由得臉上變色，但大吃一驚，這一驚非同小可。韋小寶急忙跳起身來，噗的一聲，坐入房中，從掌櫃台踢了一腳，大叫：「拿酒來，拿酒來！」\\n他一鑽入房中，立即縮頭不見有人，立即縮頭走出，只聽那'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <html>\n",
       "    <head>\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
       "    <style>\n",
       "    * {\n",
       "      box-sizing: border-box;\n",
       "    }\n",
       "\n",
       "    /* Create two unequal columns that floats next to each other */\n",
       "    .column {\n",
       "      float: left;\n",
       "      padding: 10px;\n",
       "    }\n",
       "\n",
       "    .left {\n",
       "      width: 20%;\n",
       "    }\n",
       "\n",
       "    .right {\n",
       "      width: 80%;\n",
       "    }\n",
       "\n",
       "    /* Clear floats after the columns */\n",
       "    .row:after {\n",
       "      content: \"\";\n",
       "      display: table;\n",
       "      clear: both;\n",
       "    }\n",
       "    </style>\n",
       "    </head>\n",
       "    <body>\n",
       "\n",
       "    <div style=\"background-color:#FFFFF0 !important\">\n",
       "        <div class=\"row\">\n",
       "          <div class=\"column left\">\n",
       "            <h3 style=\"color: #bfbaba;text-align:center\">\n",
       "                GPT-2看了這個標題的內容：\n",
       "                《「Cybertrunk」將於《電馭叛客 2077》登場?》<br/>\n",
       "                \n",
       "            </h2>\n",
       "          </div>\n",
       "          <div class=\"column right\">\n",
       "            <h3 style=\"color: #708090;line-height: 1.5\">行事風格向來不按牌理出牌的特斯拉汽車執行長伊隆馬斯克 (Elon Musk) 在上週的發表會上發表了一台造型相當前衛的全新車種－「The Cybertruck」。這台充滿Cyberpunk風格的全新電動車標榜著環保的特性，以及防彈的強化玻璃，即使在發表會上出了點小包，一砸就出現裂痕。然而，即使無法購買這台真車的玩家們，也許有機會在《電馭叛客 2077》中駕駛這台獨特的汽車，奔馳於遊戲中的「夜城」(Night City) 街道。</h3>\n",
       "          </div>\n",
       "        </div>\n",
       "\n",
       "        <hr/>\n",
       "\n",
       "        <div class=\"row\">\n",
       "          <div class=\"column left\">\n",
       "            <h3 style=\"color: #00477D;text-align:center\">\n",
       "                \n",
       "                GPT2說...\n",
       "            </h2>\n",
       "          </div>\n",
       "          <div class=\"column right\">\n",
       "            <h3 style=\"color: #006374;line-height: 1.5\">行事風格向來不按牌理出牌的特斯拉汽車執行長伊隆馬斯克(el##onmu##sk)在上週的發表會上發表了一台造型相當前衛的全新車種－「thec##y##bert##ru##ck」。這台充滿c##y##ber##pu##nk風格的全新電動車標榜著環保的特性，以及防彈的強化玻璃，即使在發表會上出了點小包，一砸就出現裂痕。然而，即使無法購買這台真車的玩家們，也許有機會在《電馭叛客2077》中駕駛這台獨特的汽車，奔馳於遊戲中的「夜城」(nightcity)街道。\n",
       "精忠之故鰲拜專踢了一團亮，如獲滅跡，當然有人前來投靠，勢道極緩慢，守到天明時，鄰近府的門戶溝稍停，有人推門推門進去。他見進來，當下滿是鹽擔，當下滿滿滿了一副弓箭的大小門坐在凳上，每人手上都是銬，一面團黑漆，穿了一條小門，就是一副弓彈打造得精鋼熟的模樣。\n",
       "廳上眾鹽梟見了這等大聲勢，紛紛鼓掌。安提督府中老兄贊道：「韋香主，你天明，果然有刺客。」余人一聽，都是又驚又喜，又是慚愧。老三道：「這批匪徒大會聚會，你天明日到老來，是不是來了嗎？」韋小寶笑道：「倒不是有點門戶，比之我做戲，這個夢想做戲的會唱戲，太也老是纏夾不牢，沒想要犯罪。這叫做老成，是擺明瞭料得很。」\n",
       "忽聽得廳外有人壓低聲說道：「進來。」諸鹽梟響聲中，一齊擁進，大家跳上桌來，瞧著「賊廝鳥」的模樣，有些手腳都拿著鬼頭刀。大家眼見那些鹽商人平日之事不知聞。\n",
       "韋小寶震於鹽稅甚多，討了些錢鹽稅，弄得本錢生意，十幾只鹽稅一濫，沒多幾便加一錢稅，何必多結幾條人命？突然見有聲音一變，不由得臉上變色，但大吃一驚，這一驚非同小可。韋小寶急忙跳起身來，噗的一聲，坐入房中，從掌櫃台踢了一腳，大叫：「拿酒來，拿酒來！」\n",
       "他一鑽入房中，立即縮頭不見有人，立即縮頭走出，只聽那 ...</h3>\n",
       "\n",
       "          </div>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    </body>\n",
       "    </html>\n",
       "\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 視覺化自注意力機制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title BertViz wrapper\n",
    "def call_html():\n",
    "  import IPython\n",
    "  display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min\",\n",
    "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "      '''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertviz import head_view as show_head\n",
    "from bertviz import model_view as show_model\n",
    "from bertviz import neuron_view as show_neuron\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import GPT2Tokenizer, GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from bertviz.pytorch_transformers_attn import BertModel, BertTokenizer\n",
    "#from bertviz.head_view_bert import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from bertviz.pytorch_transformers_attn import GPT2Model\n",
    "#from bertviz.head_view import show as show_head\n",
    "#from bertviz.model_view import show as show_model\n",
    "#from bertviz.neuron_view import show as show_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_html(view):\n",
    "    import IPython\n",
    "    if view in ['model', 'neuron']:\n",
    "        display(IPython.core.display.HTML('''\n",
    "             <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "             <script>\n",
    "               requirejs.config({\n",
    "                 paths: {\n",
    "                   base: '/static/base',\n",
    "                   \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min\",\n",
    "                   jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
    "                 },\n",
    "               });\n",
    "             </script>\n",
    "        '''))\n",
    "    else:\n",
    "        display(IPython.core.display.HTML('''\n",
    "             <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "             <script>\n",
    "               requirejs.config({\n",
    "                 paths: {\n",
    "                   base: '/static/base',\n",
    "                   \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n",
    "                   jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
    "                 },\n",
    "               });\n",
    "             </script>\n",
    "       '''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef show(model, tokenizer, text, view, model_type='gpt2'):\\n    call_html(view)\\n    show_func = {'head': show_head, 'model': show_model, 'neuron': show_neuron}\\n    show_func[view](model, model_type, tokenizer, text)\\n    \""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''不用了'''\n",
    "'''\n",
    "def show(model, tokenizer, text, view, model_type='gpt2'):\n",
    "    call_html(view)\n",
    "    show_func = {'head': show_head, 'model': show_model, 'neuron': show_neuron}\n",
    "    show_func[view](model, model_type, tokenizer, text)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef show(model, tokenizer, text, view, model_type='gpt2'):\\n    call_html(view)\\n    model_version = 'gpt2'\\n    model = GPT2Model.from_pretrained(model_version, output_attentions=True)\\n    tokenizer = GPT2Tokenizer.from_pretrained(model_version)\\n    inputs = tokenizer.encode_plus(text, return_tensors='pt', add_special_tokens=True)\\n    input_ids = inputs['input_ids']\\n    token_type_ids = inputs['token_type_ids']\\n    attention = model(input_ids, token_type_ids=token_type_ids)[-1]\\n    input_id_list = input_ids[0].tolist() # Batch index 0\\n    tokens = tokenizer.convert_ids_to_tokens(input_id_list)\\n    show_func = {'head': show_head, 'model': show_model, 'neuron': show_neuron}\\n    show_func[view](attention, tokens)\\n    \""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''不用了'''\n",
    "'''\n",
    "def show(model, tokenizer, text, view, model_type='gpt2'):\n",
    "    call_html(view)\n",
    "    model_version = 'gpt2'\n",
    "    model = GPT2Model.from_pretrained(model_version, output_attentions=True)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_version)\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt', add_special_tokens=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "    token_type_ids = inputs['token_type_ids']\n",
    "    attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n",
    "    input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "    show_func = {'head': show_head, 'model': show_model, 'neuron': show_neuron}\n",
    "    show_func[view](attention, tokens)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(text, view, model_type='gpt2'):\n",
    "    call_html(view)\n",
    "    model_version = 'gpt2'\n",
    "    model = GPT2Model.from_pretrained(model_version, output_attentions=True)\n",
    "    model.to('cpu')\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_version)\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt', add_special_tokens=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "    token_type_ids = inputs['token_type_ids']\n",
    "    attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n",
    "    input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "    show_func = {'head': show_head, 'model': show_model, 'neuron': show_neuron}\n",
    "    show_func[view](attention, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_head_view(text, model_type='gpt2'):\n",
    "    call_html(view)\n",
    "    model_version = 'gpt2'\n",
    "    model = GPT2Model.from_pretrained(model_version, output_attentions=True)\n",
    "    model.to('cpu')\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_version)\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt', add_special_tokens=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "    token_type_ids = inputs['token_type_ids']\n",
    "    attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n",
    "    input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "    show_head(attention, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model_view(text, model_type='gpt2'):\n",
    "    call_html(view)\n",
    "    model_version = 'gpt2'\n",
    "    model = GPT2Model.from_pretrained(model_version, output_attentions=True)\n",
    "    model.to('cpu')\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_version)\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt', add_special_tokens=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "    token_type_ids = inputs['token_type_ids']\n",
    "    attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n",
    "    input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "    show_model(attention, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt2_model = GPT2Model.from_pretrained('.')\n",
    "#gpt2_model.to('cpu')\n",
    "#gpt2_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 選擇視覺化方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title head 模式\n",
    "#text = u'小明今天沒來，聽說他生病了'\n",
    "text = 'Mary at the store, she bought apples, oranges, bananas,'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary at the store, she bought apples, oranges, bananas,\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how(gpt2_model, tokenizer, text, view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'view' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-33640991ea60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_head_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-bf098d23eb01>\u001b[0m in \u001b[0;36mshow_head_view\u001b[0;34m(text, model_type)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_head_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gpt2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcall_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gpt2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'view' is not defined"
     ]
    }
   ],
   "source": [
    "show_head_view(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title model 模式\n",
    "show_model_view(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title neuron 模式\n",
    "\n",
    "#view = 'neuron'\n",
    "#show(text, view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertviz.transformers_neuron_view import GPT2Model, GPT2Tokenizer\n",
    "from bertviz.neuron_view import show as show_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'gpt2'\n",
    "model_version = 'gpt2'\n",
    "model = GPT2Model.from_pretrained(model_version)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_neuron(model, model_type, tokenizer, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
