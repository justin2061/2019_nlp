{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "from attention_seq2seq import AttentionSeq2seq\n",
    "from seq2seq import Seq2seq\n",
    "from peeky_seq2seq import PeekySeq2seq\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 觀察資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "september 27, 1994           _1994-09-27\n",
      "August 19, 2003              _2003-08-19\n",
      "2/10/93                      _1993-02-10\n",
      "10/31/90                     _1990-10-31\n",
      "TUESDAY, SEPTEMBER 25, 1984  _1984-09-25\n",
      "JUN 17, 2013                 _2013-06-17\n",
      "april 3, 1996                _1996-04-03\n",
      "October 24, 1974             _1974-10-24\n",
      "AUGUST 11, 1986              _1986-08-11\n",
      "February 16, 2015            _2015-02-16\n",
      "October 12, 1988             _1988-10-12\n",
      "6/3/73                       _1973-06-03\n",
      "Sep 30, 1981                 _1981-09-30\n",
      "June 19, 1977                _1977-06-19\n",
      "OCTOBER 22, 2005             _2005-10-22\n"
     ]
    }
   ],
   "source": [
    "!head -15 dataset/date.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立 Attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-06 18:06:10.191632\n",
      "| epoch 1 |  iter 1 / 351 | time 0[s] | loss 4.08\n",
      "| epoch 1 |  iter 21 / 351 | time 7[s] | loss 3.09\n",
      "| epoch 1 |  iter 41 / 351 | time 17[s] | loss 1.90\n",
      "| epoch 1 |  iter 61 / 351 | time 28[s] | loss 1.72\n",
      "| epoch 1 |  iter 81 / 351 | time 41[s] | loss 1.46\n",
      "| epoch 1 |  iter 101 / 351 | time 53[s] | loss 1.19\n",
      "| epoch 1 |  iter 121 / 351 | time 63[s] | loss 1.14\n",
      "| epoch 1 |  iter 141 / 351 | time 77[s] | loss 1.09\n",
      "| epoch 1 |  iter 161 / 351 | time 88[s] | loss 1.06\n",
      "| epoch 1 |  iter 181 / 351 | time 114[s] | loss 1.04\n",
      "| epoch 1 |  iter 201 / 351 | time 135[s] | loss 1.03\n",
      "| epoch 1 |  iter 221 / 351 | time 151[s] | loss 1.02\n",
      "| epoch 1 |  iter 241 / 351 | time 161[s] | loss 1.02\n",
      "| epoch 1 |  iter 261 / 351 | time 171[s] | loss 1.01\n",
      "| epoch 1 |  iter 281 / 351 | time 183[s] | loss 1.00\n",
      "| epoch 1 |  iter 301 / 351 | time 200[s] | loss 1.00\n",
      "| epoch 1 |  iter 321 / 351 | time 211[s] | loss 1.00\n",
      "| epoch 1 |  iter 341 / 351 | time 221[s] | loss 1.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "val acc 0.000%\n",
      "2022-05-06 18:11:59.189366\n",
      "| epoch 2 |  iter 1 / 351 | time 0[s] | loss 1.00\n",
      "| epoch 2 |  iter 21 / 351 | time 14[s] | loss 1.00\n",
      "| epoch 2 |  iter 41 / 351 | time 25[s] | loss 0.99\n",
      "| epoch 2 |  iter 61 / 351 | time 36[s] | loss 0.99\n",
      "| epoch 2 |  iter 81 / 351 | time 48[s] | loss 0.99\n",
      "| epoch 2 |  iter 101 / 351 | time 58[s] | loss 0.99\n",
      "| epoch 2 |  iter 121 / 351 | time 68[s] | loss 0.99\n",
      "| epoch 2 |  iter 141 / 351 | time 77[s] | loss 0.98\n",
      "| epoch 2 |  iter 161 / 351 | time 86[s] | loss 0.98\n",
      "| epoch 2 |  iter 181 / 351 | time 97[s] | loss 0.97\n",
      "| epoch 2 |  iter 201 / 351 | time 113[s] | loss 0.95\n",
      "| epoch 2 |  iter 221 / 351 | time 164[s] | loss 0.94\n",
      "| epoch 2 |  iter 241 / 351 | time 220[s] | loss 0.90\n"
     ]
    }
   ],
   "source": [
    "# 載入資料\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 反轉輸入內容\n",
    "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "\n",
    "# 設定超參數\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 256\n",
    "batch_size = 128\n",
    "max_epoch = 10\n",
    "max_grad = 5.0\n",
    "\n",
    "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    print(datetime.datetime.now())\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse=True)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('val acc %.3f%%' % (acc * 100))\n",
    "\n",
    "\n",
    "model.save_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪圖\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.xlim(0, 11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立一般的seq2seq 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s2s = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model_s2s, optimizer)\n",
    "\n",
    "acc_list_s2s = []\n",
    "for epoch in range(max_epoch):\n",
    "    print(datetime.datetime.now())\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model_s2s, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse=True)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list_s2s.append(acc)\n",
    "    print('val acc %.3f%%' % (acc * 100))\n",
    "\n",
    "\n",
    "model_s2s.save_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立 Peeky seq2seq 模型\n",
    "https://hiroyuki.sano.ninja/notes/1cdcb48f-b8ed-4945-b3f6-6e189a2fa75f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ps2s = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model_ps2s, optimizer)\n",
    "\n",
    "acc_list_ps2s = []\n",
    "for epoch in range(max_epoch):\n",
    "    print(datetime.datetime.now())\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model_ps2s, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse=True)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list_ps2s.append(acc)\n",
    "    print('val acc %.3f%%' % (acc * 100))\n",
    "\n",
    "\n",
    "model_ps2s.save_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪圖\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.plot(x, acc_list_s2s, marker='s')\n",
    "plt.plot(x, acc_list_ps2s, marker='p')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.xlim(0, 11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
